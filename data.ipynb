{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_lI6vatddkR",
        "colab_type": "text"
      },
      "source": [
        "# COCO: Common Objects in Context\n",
        "\n",
        "<div align=\"left\">\n",
        "<a href=\"https://github.com/madewithml/incubator/blob/master/datasets/coco/data.ipynb\" role=\"button\"><img class=\"notebook-badge-image\" src=\"https://img.shields.io/static/v1?label=&amp;message=View%20On%20GitHub&amp;color=586069&amp;logo=github&amp;labelColor=2f363d\"></a>&nbsp;\n",
        "<a href=\"https://colab.research.google.com/github/madewithml/incubator/blob/master/coco/data.ipynb\"><img class=\"notebook-badge-image\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVozho7bdzdl",
        "colab_type": "text"
      },
      "source": [
        "## Getting started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSYXw4Phd2NO",
        "colab_type": "text"
      },
      "source": [
        "The [COCO dataset](http://cocodataset.org/#home) has over 330K images for [object detection](https://madewithml.com/topics/object-detection/), [ segmentation](https://madewithml.com/topics/segmentation/), [pose estimation](https://madewithml.com/topics/pose-estimation/), etc. There are three different opportunities here:\n",
        "\n",
        "1. Regardless of your task, don't train a model from scratch on the COCO set. Instead use pretrained models and fine-tune it on your own dataset. There are plenty of resources online for this but here are a few good ones: \n",
        "    * [TorchVision Object Detection Finetuning Tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)\n",
        "    * [Mask-RCNN and COCO transfer learning](https://www.kaggle.com/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155)\n",
        "\n",
        " With that said, you should understand what the COCO dataset looks like. This is necessary so you can map your own dataset to follow the same format so the pretrained models can train on them with minimal changes. Check out these resources for more on this:\n",
        "    *   [COCO Dataset Format - Complete Walkthrough](https://www.youtube.com/watch?v=h6s61a_pqfM)\n",
        "    *   [Creating Custom COCO Datasets](https://www.youtube.com/watch?v=jftZBfMZj8k&list=PLy-L-4xQRIuNm4tN9RIufCC6sqjuw1mAj)\n",
        "\n",
        "\n",
        "2. If you have the compute resources and want to train an object detection or segmentation model using the entire COCO dataset, feel free to do so :) So far folks on our Slack have suggested options like [Paperspace](https://gradient.paperspace.com/free-gpu), AWS student credits, etc. If you create a COCO-lite dataset and restrict it to certain classes, you do potentially do it on Google colab as well (we did this a few years ago).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZb1amSkvu2m",
        "colab_type": "text"
      },
      "source": [
        "## Project ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fc6awERygiW",
        "colab_type": "text"
      },
      "source": [
        "Though this project dataset is COCO, you're welcome to use any dataset to do any project! If you find really good datasets, feel free to share them on our #incubator Slack channel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCuTS57NNMme",
        "colab_type": "text"
      },
      "source": [
        "- **Moderate Projects**: beginners should review foundational topics such as [Convolutional Neural Networks](https://madewithml.com/topics/convolutional-neural-networks/) (CNNs). Then attempt with simple [image classification](https://madewithml.com/topics/image-classification/) with MNIST, ImageNet, etc. Then implement fine-tuned models on custom datasets and improve performance with techniques like computer vision focused [data augmentation](https://madewithml.com/search-results/?tags=computer-vision&tags=data-augmentation).\n",
        "\n",
        "    - **[Object detection](https://madewithml.com/topics/object-detection/)**: Object detection: detect key items in the image.\n",
        "\n",
        "    - **[Image segmentation](https://madewithml.com/topics/segmentation/)**: segment (semantic or instance) key items in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfjirvcPOuac",
        "colab_type": "text"
      },
      "source": [
        "- **Challenging projects**\n",
        "    - [**Image captioning**](https://madewithml.com/topics/image-captioning/): generate captions for each image w/ inputs such as style, tone, etc.\n",
        "\n",
        "    - [**panoptic segmentation**](http://cocodataset.org/#panoptic-2019): identify everything in the image.\n",
        "\n",
        "    - [**Image generation**](https://madewithml.com/topics/image-generation/): generate an image from a caption, traditionally using [generative adversarial networks](https://madewithml.com/topics/generative-adversarial-networks/) (GANs).\n",
        "    - [**End-to-end object detection**](https://madewithml.com/projects/993/detr-end-to-end-object-detection-with-transformers/): object detection as a direct set problem (without supression or anchor generation) using transformers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3KZjgfow4Oo",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "Learn, explore and build at <a href=\"https://madewithml.com/\">Made With ML</a>.\n",
        "\n",
        "<div align=\"left\">\n",
        "<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://github.com/madewithml/basics\"><img src=\"https://img.shields.io/github/stars/madewithml/basics.svg?style=social&label=Star\"></a>&nbsp;\n",
        "<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://www.linkedin.com/company/madewithml\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n",
        "<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://www.youtube.com/channel/UCaVCnFQXS7PYMoYZu3KdC0Q?sub_confirmation=1\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=YouTube&logo=youtube&style=social\"></a>&nbsp;<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://twitter.com/madewithml\"><img src=\"https://img.shields.io/twitter/follow/madewithml.svg?label=Follow&style=social\"></a>\n",
        "</div>\n",
        "             "
      ]
    }
  ]
}